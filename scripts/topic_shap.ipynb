{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import *\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset go_emotions (/home/steinad/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d)\n",
      "Found cached dataset go_emotions (/home/steinad/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d)\n",
      "Found cached dataset go_emotions (/home/steinad/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d)\n",
      "Loading cached processed dataset at /home/steinad/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d/cache-87b5621d3c9d3b14.arrow\n",
      "Loading cached processed dataset at /home/steinad/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d/cache-73f6da48115296a3.arrow\n",
      "Loading cached processed dataset at /home/steinad/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d/cache-d79b641356104162.arrow\n",
      "Loading cached processed dataset at /home/steinad/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d/cache-b3d3995d603b0e7d.arrow\n",
      "Loading cached processed dataset at /home/steinad/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d/cache-0561288458021b5b.arrow\n",
      "Loading cached processed dataset at /home/steinad/.cache/huggingface/datasets/go_emotions/simplified/0.0.0/2637cfdd4e64d30249c3ed2150fa2b9d279766bfcd6a809b9f085c61a90d776d/cache-9d521ebf4082fb42.arrow\n"
     ]
    }
   ],
   "source": [
    "config = {\"dataset\": \"goemotions\", \"topics\": \"lda\"}\n",
    "data_train, data_val, data_test = load_data(config)\n",
    "x = [data_test[i]['sentence'] for i in range(100)]\n",
    "# x = [xi for xi in x if len(xi.split()) > 1]\n",
    "# topics, word2idx = get_topics(config, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 31, 28)\n"
     ]
    }
   ],
   "source": [
    "dataset = \"goemotions\"\n",
    "config = {\"dataset\": dataset, \"topics\": \"lda\"}\n",
    "topics, word2idx = get_topics(config, x)\n",
    "# roberta_shap_vals = load(\"shap_vals_gpt2_sst2\")\n",
    "roberta_topic_vals = load(f\"topic_vals_distilroberta_{dataset}_lda\").reshape(-1, 31, 28)\n",
    "roberta_word_vals = load(f\"word_vals_distilroberta_{dataset}_lda\")\n",
    "# gpt2_topic_vals = load(f\"topic_vals_gpt2_{dataset}_lda\").reshape(-1, 31)\n",
    "# gpt2_word_vals = load(f\"word_vals_gpt2_{dataset}_lda\")\n",
    "print(roberta_topic_vals.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ['oh', 'day', 'happy', 'shit', 'fuck', 'fucking', 'man', 'haha', 'yeah', 'one']\n",
      "1 ['post', 'here', 'comment', 'sub', 'read', 'sorry', 'from', 'thanks', 'got', 'reddit']\n",
      "2 ['name', 'game', 'one', 'watch', 'show', 'great', 'favorite', 'play', 'fun', 'video']\n",
      "3 ['name', 'we', 'game', 'our', 'team', 'him', 'play', 'win', 'would', 'season']\n",
      "4 ['their', 'money', 'because', 'people', 'pay', 'we', 'our', 'or', 'government', 'want']\n",
      "5 ['good', \"i'm\", 'sorry', 'hope', 'glad', 'luck', 'am', \"you're\", 'best', 'hear']\n",
      "6 ['them', 'will', 'take', 'from', \"don't\", 'stop', 'please', 'yourself', 'get', 'or']\n",
      "7 ['thanks', 'thank', 'much', ':)', 'very', \"i'll\", 'really', 'appreciate', 'try', 'good']\n",
      "8 ['would', 'did', 'say', \"didn't\", 'know', 'same', 'said', 'thought', 'thing', 'were']\n",
      "9 ['people', 'who', 'their', 'them', 'other', 'because', 'name', 'these', 'there', 'by']\n",
      "10 ['would', 'one', 'those', 'only', 'an', 'we', 'get', 'also', 'which', 'why']\n",
      "11 ['up', 'down', 'when', 'back', 'there', 'go', 'out', 'his', 'end', 'over']\n",
      "12 ['people', 'who', 'being', 'women', 'by', 'men', 'their', 'an', 'how', 'because']\n",
      "13 [\"don't\", 'know', 'don', 'think', 'how', 'we', 'people', 'want', 'why', 'dont']\n",
      "14 ['got', 'his', 'were', 'would', 'had', 'get', 'could', 'him', 'off', 'into']\n",
      "15 ['them', 'get', 'off', 'go', 'too', 'we', 'some', 'or', 'into', 'eat']\n",
      "16 ['how', \"can't\", 'out', 'did', 'see', 'wait', 'does', 'why', 'get', 'else']\n",
      "17 [\"i'm\", \"you're\", \"doesn't\", 'being', 'or', 'wrong', 'why', 'an', 'mean', 'does']\n",
      "18 ['pretty', 'good', \"that's\", 'look', 'looks', 'really', 'cool', 'great', 'bad', 'too']\n",
      "19 ['name', 'his', 'him', \"he's\", 'guy', 'has', 'oh', 'damn', 'from', 'who']\n",
      "20 ['an', 'or', 'any', 'there', 'way', 'would', 'use', 'interesting', 'actually', \"that's\"]\n",
      "21 ['get', 'will', 'out', 'go', 'some', 'need', 'maybe', 'keep', 'going', 'back']\n",
      "22 ['years', 'year', 'old', 'last', 'ago', 'still', 'time', 'few', 'long', 'days']\n",
      "23 ['she', 'her', 'name', \"she's\", 'girl', 'his', 'mom', 'who', 'him', 'when']\n",
      "24 [\"i'm\", 'right', 'now', 'name', 'sure', 're', 'think', 'there', 'getting', \"you're\"]\n",
      "25 ['out', 'some', 'weird', 'its', 'lol', 'when', 'from', 'also', \"that's\", 'hot']\n",
      "26 ['from', 'there', 'live', 'where', 'world', 'place', 'here', 'we', 'new', 'our']\n",
      "27 ['been', \"i've\", 'never', 'has', 'ever', 've', 'seen', 'had', 'one', 'heard']\n",
      "28 ['too', 'time', 'feel', 'really', 'bad', 'one', 'every', 'same', 'way', 'only']\n",
      "29 ['more', 'than', 'better', 'much', 'makes', 'even', 'think', 'less', 'would', 'way']\n"
     ]
    }
   ],
   "source": [
    "base_path = \"../scripts/\"\n",
    "topics_matrix_df = pd.read_csv(base_path + (\"../data/processed_LDA_files/\" + dataset + \"_50.csv\"))\n",
    "word2idx = dict(zip(topics_matrix_df[\"words\"], range(len(topics_matrix_df[\"words\"]))))\n",
    "topics_matrix_df.drop(columns=[\"words\"], inplace=True)\n",
    "topics_matrix_df = topics_matrix_df.T\n",
    "topics_raw = topics_matrix_df.to_numpy()\n",
    "sorted_words = np.argsort(topics_raw, axis=1)\n",
    "idx2word = {i: word for word, i in word2idx.items()}\n",
    "for i in range(topics_raw.shape[0]):\n",
    "    print(i, [idx2word[word_idx] for word_idx in sorted_words[i][::-1][:10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.out_proj.bias', 'classifier.out_proj.weight', 'classifier.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "They\n",
      "for\n",
      "of\n",
      "and\n",
      "on\n",
      "to\n",
      "the\n",
      "afterlife.\n",
      "[0.2003762051463127, -0.15281378291547298, -0.20729783363640308, 0.11858675349503756, -0.08425124082714319, 0.007137363776564598, 0.01972377859055996, 0.005102875952919324, -0.004639976347486178, -0.005184094111124675, -0.008481353521347046, 0.09562041610479355, -0.0773390680551529, -0.006970260292291641, 0.0005980096757411957, 0.0005573878685633341, -0.023366148273150124]\n",
      "[ 0.         -0.01104525  0.00581416 -0.01441691  0.00483219 -0.00590993\n",
      "  0.01627969 -0.09985756 -0.00693229  0.00785239  0.09768289  0.\n",
      "  0.          0.         -0.04073291 -0.00318874 -0.06766862  0.\n",
      "  0.          0.00771972  0.00675133  0.         -0.00959804 -0.00306536\n",
      "  0.         -0.00611068 -0.03786474 -0.09854012 -0.04376533  0.0013255\n",
      "  0.17779764]\n",
      "-0.12264096736907959\n",
      "-0.12264096736907962\n",
      "They got bored from haunting earth for thousands of years and ultimately moved on to the afterlife.\n"
     ]
    }
   ],
   "source": [
    "model1, _ = load_models(config)\n",
    "explainer = shap.Explainer(model1, padding=\"max_length\", truncation=True, max_length=512)\n",
    "idx = 4\n",
    "tok_sample = explainer.masker.data_transform(x[idx])[0]\n",
    "print(tok_sample)\n",
    "_, words = word_shap(tok_sample, np.zeros(len(tok_sample)))\n",
    "for tok in words:\n",
    "    if tok not in word2idx:\n",
    "        print(tok)\n",
    "print(roberta_word_vals[idx])\n",
    "print(roberta_topic_vals[idx])\n",
    "print(sum(roberta_word_vals[idx]))\n",
    "print(sum(roberta_topic_vals[idx]))\n",
    "print(x[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.35931513 0.74429793 1.18468939 0.46055958 0.3257553  1.45500909\n",
      " 1.02774093 1.00907149 1.04191695 0.51910663]\n",
      "5\n",
      "[30 25 19]\n",
      "29 here 's a british flick gleefully unconcerned with plausibility , yet just as determined to entertain you .\n"
     ]
    }
   ],
   "source": [
    "X = roberta_topic_vals / np.sum(roberta_topic_vals, axis=1, keepdims=True)\n",
    "kmeans = KMeans(n_clusters=10).fit(X)\n",
    "clabels = kmeans.labels_\n",
    "\n",
    "diffs = np.zeros(10)\n",
    "for c in range(10):\n",
    "    diffs[c] = np.sum(np.abs(np.sum(roberta_topic_vals[clabels == c], axis=0) - np.sum(gpt2_topic_vals[clabels == c], axis=0)) / np.sum(clabels == c))\n",
    "most_diff_cluster = np.argsort(diffs)[::-1][0]\n",
    "print(diffs)\n",
    "print(most_diff_cluster)\n",
    "diff = np.abs(np.sum(roberta_topic_vals[clabels == most_diff_cluster], axis=0) - np.sum(gpt2_topic_vals[clabels == most_diff_cluster], axis=0)) / np.sum(clabels == most_diff_cluster)\n",
    "print(np.argsort(diff)[::-1][:3])\n",
    "\n",
    "for idx in np.nonzero(clabels == most_diff_cluster)[0]:\n",
    "    print(idx, x[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.18468939 1.24345609 1.34729508 1.45500909 1.50728886]\n"
     ]
    }
   ],
   "source": [
    "diffs = np.sum(np.abs(roberta_topic_vals - gpt2_topic_vals), axis=1)\n",
    "biggest_diff = np.argsort(diffs)\n",
    "print(diffs[biggest_diff[-5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here 's a british flick gleefully unconcerned with plausibility , yet just as determined to entertain you .\n",
      "topic_19: -0.1553845656310764\n",
      "topic_30: -0.10612585631315596\n",
      "topic_25: -0.0935087014799168\n",
      "topic_14: -0.03646532557338526\n",
      "topic_15: -0.01593457268374577\n",
      "topic_22: 0.02807360821965514\n",
      "topic_1: 0.045695628701287475\n",
      "topic_21: 0.0492626937546679\n",
      "topic_26: 0.09268165987427164\n",
      "topic_10: 0.22321857630317818\n",
      "0.06044590473175046\n",
      "\n",
      "topic_19: -0.3872873015917917\n",
      "topic_0: 0.0\n",
      "topic_17: 0.0\n",
      "topic_16: 0.0\n",
      "topic_13: 0.0\n",
      "topic_15: 0.029227123956237402\n",
      "topic_4: 0.03711597906478719\n",
      "topic_26: 0.05891144657342237\n",
      "topic_25: 0.14575828416624173\n",
      "topic_30: 0.3104190980375279\n",
      "0.358201801776886\n"
     ]
    }
   ],
   "source": [
    "ind = 29 #biggest_diff[-1]\n",
    "print(x[ind])\n",
    "topic_names = np.array([f\"topic_{i}\" for i in range(36)])\n",
    "topic_values, sorted_names = sort_shap(roberta_topic_vals[ind], topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")\n",
    "print(np.sum(topic_values))\n",
    "\n",
    "print()\n",
    "topic_values, sorted_names = sort_shap(gpt2_topic_vals[ind], topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")\n",
    "print(np.sum(topic_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_25: 0.006110679304319723\n",
      "topic_15: 0.006897511634863846\n",
      "topic_12: 0.009089059525776176\n",
      "topic_22: 0.012098819741992079\n",
      "topic_21: 0.015178255319194547\n",
      "topic_1: 0.2552797217033191\n",
      "topic_26: 0.5835412084444859\n",
      "topic_7: 0.6627277899339665\n",
      "topic_5: 1.5791001013991892\n",
      "topic_30: 4.3985357037551385\n"
     ]
    }
   ],
   "source": [
    "topic_names = np.array([f\"topic_{i}\" for i in range(36)])\n",
    "roberta_feat_imp = np.sum(np.abs(roberta_topic_vals), axis=0)\n",
    "# gpt2_feat_imp = np.sum(np.abs(gpt2_topic_vals), axis=0)\n",
    "\n",
    "topic_values, sorted_names = sort_shap(roberta_feat_imp, topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")\n",
    "\n",
    "# print()\n",
    "# topic_values, sorted_names = sort_shap(gpt2_feat_imp, topic_names)\n",
    "# for i in range(5):\n",
    "#     print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "# for i in range(5, 0, -1):\n",
    "#     print(f\"{sorted_names[-i]}: {topic_values[-i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lexx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "643c8de94e1a6f14c10796bc4742cda7b866ba13d8a7cf37541d0f9d17d91a71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
