{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Can't initialize NVML\n"
     ]
    }
   ],
   "source": [
    "from src.utils import *\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_topic_vals = load(\"topic_vals_distilroberta_sst2_neurallda\").reshape(35, -1).T\n",
    "roberta_word_vals = load(\"word_vals_distilroberta_sst2_neurallda\")\n",
    "gpt2_topic_vals = load(\"topic_vals_gpt2_sst2_neurallda\").reshape(35, -1).T\n",
    "gpt2_word_vals = load(\"word_vals_gpt2_sst2_neurallda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.06844324780547101, -0.03441399789374808, -0.03482532954734305, -0.035617534881052765, -0.035795216327128204, -0.0342250213674877, -0.03552672720473746, 0.07436558523255846, 0.08230492391664049, 0.05901205458718797, 0.05697405257302782, 0.07659329392987749, 0.07571579434949419, 0.07957713224965593, 0.07845954516011736, -0.031984785051079274, -0.03219048068019915, -0.03218735143634844, -0.03144920751545, -0.034870956193339506, -0.03588083768976895, -0.034811351548564115]\n",
      "0.07078033685684201\n",
      "-0.0022241838531723785\n"
     ]
    }
   ],
   "source": [
    "print(roberta_word_vals[12])\n",
    "print(sum(roberta_word_vals[12]))\n",
    "print(sum(roberta_topic_vals[12]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.05935103 0.06270623 0.06711678 0.06758894 0.08479623]\n"
     ]
    }
   ],
   "source": [
    "diffs = np.sum(np.abs(roberta_topic_vals - gpt2_topic_vals), axis=1)\n",
    "biggest_diff = np.argsort(diffs)\n",
    "print(diffs[biggest_diff[-5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset glue (/home/steinad/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Found cached dataset glue (/home/steinad/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n",
      "Found cached dataset glue (/home/steinad/.cache/huggingface/datasets/glue/sst2/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n"
     ]
    }
   ],
   "source": [
    "config = {\"dataset\": \"sst2\", \"topics\": \"neurallda\"}\n",
    "data_train, data_val, data_test = load_data(config)\n",
    "x = [data_test[i]['sentence'] for i in range(100)]\n",
    "# x = [xi for xi in x if len(xi.split()) > 1]\n",
    "# topics, word2idx = get_topics(config, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "watching the film is like reading a times portrait of grief that keeps shifting focus to the journalist who wrote it .\n",
      "topic_12: -0.0014262526047857803\n",
      "topic_3: -0.00042621047593761175\n",
      "topic_26: -9.787188167671155e-05\n",
      "topic_2: -5.1724569786167414e-05\n",
      "topic_0: -3.9811148712321695e-05\n",
      "topic_21: 4.6305975717451755e-06\n",
      "topic_1: 6.806552625306536e-06\n",
      "topic_33: 1.2902597674472122e-05\n",
      "topic_19: 1.5473285901018953e-05\n",
      "topic_23: 2.0242076582350233e-05\n",
      "-0.002224183853172378\n",
      "\n",
      "topic_3: -0.0023406865549638954\n",
      "topic_12: -0.0016128547624960816\n",
      "topic_26: -4.426915723135241e-05\n",
      "topic_0: -3.321126083180247e-05\n",
      "topic_16: -2.555687154099849e-05\n",
      "topic_22: 1.3635210672744357e-05\n",
      "topic_5: 1.4533969500273924e-05\n",
      "topic_32: 1.5006769603963799e-05\n",
      "topic_19: 2.0403530211831316e-05\n",
      "topic_33: 5.473252835130333e-05\n",
      "-0.003999972371069049\n"
     ]
    }
   ],
   "source": [
    "ind = 12\n",
    "print(x[ind])\n",
    "topic_names = np.array([f\"topic_{i}\" for i in range(35)])\n",
    "topic_values, sorted_names = sort_shap(roberta_topic_vals[ind], topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")\n",
    "print(np.sum(topic_values))\n",
    "\n",
    "print()\n",
    "topic_values, sorted_names = sort_shap(gpt2_topic_vals[ind], topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")\n",
    "print(np.sum(topic_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic_12: 0.0039248079911657395\n",
      "topic_19: 0.00437228403054702\n",
      "topic_23: 0.007083105440961838\n",
      "topic_21: 0.007207122350407736\n",
      "topic_4: 0.007945969590827344\n",
      "topic_27: 0.027161570806750353\n",
      "topic_10: 0.02861819733096396\n",
      "topic_0: 0.033209786853810354\n",
      "topic_9: 0.03376273036539565\n",
      "topic_14: 0.04494498606418069\n",
      "\n",
      "topic_19: 0.0034037410940360438\n",
      "topic_21: 0.0044669875053348585\n",
      "topic_12: 0.0046271445160920525\n",
      "topic_4: 0.005875169953940336\n",
      "topic_13: 0.0061624909836076915\n",
      "topic_11: 0.026181167936668418\n",
      "topic_3: 0.028924082971533087\n",
      "topic_2: 0.034245801383795314\n",
      "topic_0: 0.03728624489157434\n",
      "topic_26: 0.04269658075044573\n"
     ]
    }
   ],
   "source": [
    "roberta_feat_imp = np.sum(np.abs(roberta_topic_vals), axis=0)\n",
    "gpt2_feat_imp = np.sum(np.abs(gpt2_topic_vals), axis=0)\n",
    "\n",
    "topic_values, sorted_names = sort_shap(roberta_feat_imp, topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")\n",
    "\n",
    "print()\n",
    "topic_values, sorted_names = sort_shap(gpt2_feat_imp, topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lexx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "643c8de94e1a6f14c10796bc4742cda7b866ba13d8a7cf37541d0f9d17d91a71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
