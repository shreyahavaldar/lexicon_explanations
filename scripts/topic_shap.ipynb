{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steinad/anaconda3/envs/lexx/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.utils import save, load\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "distilbert_topic_vals = load(\"topic_vals_distilbertbase_sst2\").reshape(872, 73)\n",
    "robertalarge_topic_vals = load(\"topic_vals_robertalarge_sst2\").reshape(872, 73)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.36153851 1.37051871 1.47261364 1.48859745 1.70616717]\n"
     ]
    }
   ],
   "source": [
    "diffs = np.sum(np.abs(distilbert_topic_vals - robertalarge_topic_vals), axis=1)\n",
    "biggest_diff = np.argsort(diffs)\n",
    "print(diffs[biggest_diff[-5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/steinad/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sst2 = load_dataset(\"sst2\", split=\"validation\")\n",
    "x = [sst2[i]['sentence'] for i in range(len(sst2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACHIEVE' 'ADJ' 'ADVERB' 'AFFECT' 'AFFILIATION' 'ANGER' 'ANX' 'ARTICLE'\n",
      " 'ASSENT' 'AUXVERB' 'BIO' 'BODY' 'CAUSE' 'CERTAIN' 'COGPROC' 'COMPARE'\n",
      " 'CONJ' 'DEATH' 'DIFFER' 'DISCREP' 'DRIVES' 'FAMILY' 'FEEL' 'FEMALE'\n",
      " 'FILLER' 'FOCUSFUTURE' 'FOCUSPAST' 'FOCUSPRESENT' 'FRIEND' 'FUNCTION'\n",
      " 'HEALTH' 'HEAR' 'HOME' 'I' 'INFORMAL' 'INGEST' 'INSIGHT' 'INTERROG'\n",
      " 'IPRON' 'LEISURE' 'MALE' 'MONEY' 'MOTION' 'NEGATE' 'NEGEMO' 'NETSPEAK'\n",
      " 'NONFLU' 'NUMBER' 'PERCEPT' 'POSEMO' 'POWER' 'PPRON' 'PREP' 'PRONOUN'\n",
      " 'QUANT' 'RELATIV' 'RELIG' 'REWARD' 'RISK' 'SAD' 'SEE' 'SEXUAL' 'SHEHE'\n",
      " 'SOCIAL' 'SPACE' 'SWEAR' 'TENTAT' 'THEY' 'TIME' 'VERB' 'WE' 'WORK' 'YOU']\n"
     ]
    }
   ],
   "source": [
    "from src.pair_data import LIWCWordData\n",
    "\n",
    "def get_liwc_topics():\n",
    "    feature_groups = LIWCWordData(\n",
    "        \"../data/LIWC2015_processed.csv\",\n",
    "        split=\"train\")\n",
    "\n",
    "    print(feature_groups.groups)\n",
    "    topic_names = feature_groups.groups\n",
    "    topics = {name: set() for name in topic_names}\n",
    "    for word, groups in feature_groups:\n",
    "        for group in groups:\n",
    "            topics[group].add(word)\n",
    "    all_tokens = set().union(*topics.values())\n",
    "    word2idx = {word: i for i, word in enumerate(all_tokens)}\n",
    "    topics = np.array([[1.0 if tok in topics[topic_names[i]]\n",
    "                        else 0.0 for tok in all_tokens] for i in range(len(topic_names))])\n",
    "    topics = topics / np.sum(topics, axis=1, keepdims=True)\n",
    "    return topics, topic_names, word2idx\n",
    "\n",
    "topics, topic_names, word2idx = get_liwc_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "an entertaining , colorful , action-filled crime story with an intimate heart . \n",
      "ANGER: -1.8504402262217918e-05\n",
      "NEGEMO: -5.750461162503181e-06\n",
      "AFFECT: -3.1536017117971704e-06\n",
      "ACHIEVE: 0.0\n",
      "POWER: 0.0\n",
      "HEAR: 0.0\n",
      "PREP: 0.0005175859107903193\n",
      "SOCIAL: 0.0005255784083522601\n",
      "FUNCTION: 0.0030943426793281544\n",
      "ARTICLE: 0.5953518952809127\n",
      "0.5994619938142469\n",
      "\n",
      "ARTICLE: -1.055920267974337\n",
      "SOCIAL: -0.0013257281632984923\n",
      "FUNCTION: -0.0009159737743029677\n",
      "ACHIEVE: 0.0\n",
      "POWER: 0.0\n",
      "FOCUSPAST: 0.0\n",
      "AFFECT: 0.002035189891602397\n",
      "NEGEMO: 0.003711083865219365\n",
      "ANGER: 0.011941892437884887\n",
      "PREP: 0.031835397615878266\n",
      "-1.0086384061013536\n"
     ]
    }
   ],
   "source": [
    "def sort_shap(shap_values, feature_names):\n",
    "    sort_idx = np.argsort(shap_values)\n",
    "    return shap_values[sort_idx], feature_names[sort_idx]\n",
    "\n",
    "print(x[biggest_diff[-1]])\n",
    "topic_values, sorted_names = sort_shap(distilbert_topic_vals[biggest_diff[-1]], topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")\n",
    "print(np.sum(topic_values))\n",
    "\n",
    "print()\n",
    "topic_values, sorted_names = sort_shap(robertalarge_topic_vals[biggest_diff[-1]], topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")\n",
    "print(np.sum(topic_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lexx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "643c8de94e1a6f14c10796bc4742cda7b866ba13d8a7cf37541d0f9d17d91a71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
