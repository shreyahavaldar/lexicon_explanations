{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/steinad/anaconda3/envs/lexx/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from src.utils import save, load\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "roberta_topic_vals = load(\"topic_vals_roberta_sst2\").reshape(872, 73)\n",
    "roberta_word_vals = load(\"word_vals_roberta_sst2\")\n",
    "gpt2_topic_vals = load(\"topic_vals_gpt2_sst2\").reshape(872, 73)\n",
    "gpt2_word_vals = load(\"word_vals_gpt2_sst2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.017804070766314323, 0.017820183888618602, 0.009020082382134824, 0.00904148044960919, 0.008973233131341367, 0.008827978740761052, 0.00885760224921442, 0.008831167589256535, 0.00884090301456985, 0.0005314120879540077]\n"
     ]
    }
   ],
   "source": [
    "print(roberta_word_vals[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3.43656601 3.46910591 3.60732746 4.01513563 4.80082569]\n"
     ]
    }
   ],
   "source": [
    "diffs = np.sum(np.abs(roberta_topic_vals - gpt2_topic_vals), axis=1)\n",
    "biggest_diff = np.argsort(diffs)\n",
    "print(diffs[biggest_diff[-5:]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset sst2 (/home/steinad/.cache/huggingface/datasets/sst2/default/2.0.0/9896208a8d85db057ac50c72282bcb8fe755accc671a57dd8059d4e130961ed5)\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "sst2 = load_dataset(\"sst2\", split=\"validation\")\n",
    "x = [sst2[i]['sentence'] for i in range(len(sst2))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ACHIEVE' 'ADJ' 'ADVERB' 'AFFECT' 'AFFILIATION' 'ANGER' 'ANX' 'ARTICLE'\n",
      " 'ASSENT' 'AUXVERB' 'BIO' 'BODY' 'CAUSE' 'CERTAIN' 'COGPROC' 'COMPARE'\n",
      " 'CONJ' 'DEATH' 'DIFFER' 'DISCREP' 'DRIVES' 'FAMILY' 'FEEL' 'FEMALE'\n",
      " 'FILLER' 'FOCUSFUTURE' 'FOCUSPAST' 'FOCUSPRESENT' 'FRIEND' 'FUNCTION'\n",
      " 'HEALTH' 'HEAR' 'HOME' 'I' 'INFORMAL' 'INGEST' 'INSIGHT' 'INTERROG'\n",
      " 'IPRON' 'LEISURE' 'MALE' 'MONEY' 'MOTION' 'NEGATE' 'NEGEMO' 'NETSPEAK'\n",
      " 'NONFLU' 'NUMBER' 'PERCEPT' 'POSEMO' 'POWER' 'PPRON' 'PREP' 'PRONOUN'\n",
      " 'QUANT' 'RELATIV' 'RELIG' 'REWARD' 'RISK' 'SAD' 'SEE' 'SEXUAL' 'SHEHE'\n",
      " 'SOCIAL' 'SPACE' 'SWEAR' 'TENTAT' 'THEY' 'TIME' 'VERB' 'WE' 'WORK' 'YOU']\n"
     ]
    }
   ],
   "source": [
    "from src.pair_data import LIWCWordData\n",
    "\n",
    "def get_liwc_topics():\n",
    "    feature_groups = LIWCWordData(\n",
    "        \"../data/LIWC2015_processed.csv\",\n",
    "        split=\"train\")\n",
    "\n",
    "    print(feature_groups.groups)\n",
    "    topic_names = feature_groups.groups\n",
    "    topics = {name: set() for name in topic_names}\n",
    "    for word, groups in feature_groups:\n",
    "        for group in groups:\n",
    "            topics[group].add(word)\n",
    "    all_tokens = set().union(*topics.values())\n",
    "    word2idx = {word: i for i, word in enumerate(all_tokens)}\n",
    "    topics = np.array([[1.0 if tok in topics[topic_names[i]]\n",
    "                        else 0.0 for tok in all_tokens] for i in range(len(topic_names))])\n",
    "    topics = topics / np.sum(topics, axis=1, keepdims=True)\n",
    "    return topics, topic_names, word2idx\n",
    "\n",
    "topics, topic_names, word2idx = get_liwc_topics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "it 's hard to like a film about a guy who is utterly unlikeable , and shiner , starring michael caine as an aging british boxing promoter desperate for a taste of fame and fortune , is certainly that . \n",
      "LEISURE: -0.36569334224242755\n",
      "FUNCTION: -0.27105720183691845\n",
      "MONEY: -0.21411185965103244\n",
      "ADJ: -0.18873733102676638\n",
      "PERCEPT: -0.18630983465633832\n",
      "FOCUSPRESENT: 0.09921325059868341\n",
      "VERB: 0.09921325059868341\n",
      "AUXVERB: 0.09921325059868341\n",
      "COGPROC: 0.9411406235419841\n",
      "TENTAT: 0.9411406235419841\n",
      "-0.01598477363586448\n",
      "\n",
      "PERCEPT: -0.14441831652159903\n",
      "ADJ: -0.13117476043623966\n",
      "FEEL: -0.12668385165530482\n",
      "VERB: -0.04428620531400239\n",
      "AUXVERB: -0.04428620531400239\n",
      "RELATIV: 0.032976173363023935\n",
      "ADVERB: 0.03655655451021553\n",
      "FUNCTION: 0.12921181384431246\n",
      "ARTICLE: 0.15489520962575293\n",
      "LEISURE: 0.27505445752494306\n",
      "-0.039242565631866455\n"
     ]
    }
   ],
   "source": [
    "def sort_shap(shap_values, feature_names):\n",
    "    sort_idx = np.argsort(shap_values)\n",
    "    return shap_values[sort_idx], feature_names[sort_idx]\n",
    "\n",
    "print(x[biggest_diff[-1]])\n",
    "topic_values, sorted_names = sort_shap(roberta_topic_vals[biggest_diff[-1]], topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")\n",
    "print(np.sum(topic_values))\n",
    "\n",
    "print()\n",
    "topic_values, sorted_names = sort_shap(gpt2_topic_vals[biggest_diff[-1]], topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")\n",
    "print(np.sum(topic_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FILLER: 0.0\n",
      "FRIEND: 0.03189607823355886\n",
      "NONFLU: 0.033081506995165516\n",
      "NETSPEAK: 0.06012690665245049\n",
      "FAMILY: 0.07551659329808283\n",
      "VERB: 15.59652999899614\n",
      "AFFECT: 18.68109704727057\n",
      "FUNCTION: 56.65816143713713\n",
      "TENTAT: 139.1511898138908\n",
      "COGPROC: 146.15578183325945\n",
      "\n",
      "FILLER: 0.0\n",
      "NETSPEAK: 0.03222749590764896\n",
      "FRIEND: 0.04757091170766162\n",
      "NONFLU: 0.0950164186725323\n",
      "WE: 0.1060787855539368\n",
      "ADJ: 14.420973437055986\n",
      "COGPROC: 16.749330594025174\n",
      "AFFECT: 20.280769169058956\n",
      "FUNCTION: 46.39188136829717\n",
      "LEISURE: 262.2904466820398\n"
     ]
    }
   ],
   "source": [
    "roberta_feat_imp = np.sum(np.abs(roberta_topic_vals), axis=0)\n",
    "gpt2_feat_imp = np.sum(np.abs(gpt2_topic_vals), axis=0)\n",
    "\n",
    "topic_values, sorted_names = sort_shap(roberta_feat_imp, topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")\n",
    "\n",
    "print()\n",
    "topic_values, sorted_names = sort_shap(gpt2_feat_imp, topic_names)\n",
    "for i in range(5):\n",
    "    print(f\"{sorted_names[i]}: {topic_values[i]}\")\n",
    "for i in range(5, 0, -1):\n",
    "    print(f\"{sorted_names[-i]}: {topic_values[-i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lexx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "643c8de94e1a6f14c10796bc4742cda7b866ba13d8a7cf37541d0f9d17d91a71"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
